{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPooling1D, Flatten, Reshape, MaxPool1D, BatchNormalization, Dropout, Input, Bidirectional\n",
        "from keras.models import Sequential\n",
        "from Utils import Utils\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import keras\n",
        "#from resnet import Residual\n",
        "import math\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "class Lstm(object):\n",
        "\t#Lambda Functions - Start\n",
        "\tdef recall_m(self, y_true, y_pred):\n",
        "\t\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "\t\tpossible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "\t\trecall = true_positives / (possible_positives + K.epsilon())\n",
        "\t\treturn recall\n",
        "\n",
        "\tdef precision_m(self, y_true, y_pred):\n",
        "\t\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "\t\tpredicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\t\tprecision = true_positives / (predicted_positives + K.epsilon())\n",
        "\t\treturn precision\n",
        "\t#Lambda Functions - End\n",
        "\n",
        "\tdef __init__(self, X_tr, y_tr, X_test, y_test, model_filename = 'Cnn1D.sav', epochs = 10, batch_size = 512):\n",
        "\t\tself.epochs = epochs\n",
        "\t\tself.batch_size = batch_size\n",
        "\n",
        "\t\tblock_1_layers, block2_layers, block3_layers = 32, 16, 8\n",
        "\t\tint(math.sqrt(32))\n",
        "\n",
        "\t\t#https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f\n",
        "\t\t# For CNN, RNN and HAN\n",
        "\n",
        "\t\tself.y_tr = to_categorical(y_tr['labels'].values, dtype = \"uint8\")\n",
        "\t\tself.y_test = to_categorical(y_test['labels'].values, dtype = \"uint8\")\n",
        "\n",
        "\t\tself.X_tr = X_tr.values.reshape(X_tr.values.shape[0], X_tr.values.shape[1], 1)\n",
        "\t\tself.X_test = X_test.values.reshape(X_test.values.shape[0], X_test.values.shape[1], 1)\n",
        "\n",
        "\t\tself.model_filename = \"../model/\" + model_filename\n",
        "\n",
        "\t\t#self.y_tr.shape[1] = 1214\n",
        "\n",
        "\t\t#Define The Model\n",
        "\t\tmodel = tf.keras.Sequential()\n",
        "\t\t#model.add(Conv1D(filters=256, kernel_size=3, strides=1, activation='relu', input_shape=(self.X_tr.shape[1],1), name='block1_conv1'))\n",
        "\t\tmodel.add(Input(shape=(self.X_tr.shape[1],1), batch_size=None, name=\"Input Layer\"))\n",
        "\t\t################################################################################\n",
        "\t\t#model.add(Conv1D(filters=block_1_layers, kernel_size=5, strides=1, activation='relu', name='block1_conv1'))\n",
        "\n",
        "\t\tmodel.add(LSTM(\n",
        "\t\t\tunits = block_1_layers, activation='tanh', recurrent_activation='sigmoid',\n",
        "\t\t\tuse_bias=True, kernel_initializer='glorot_uniform',\n",
        "\t\t\trecurrent_initializer='orthogonal',\n",
        "\t\t\tbias_initializer='zeros', unit_forget_bias=True,\n",
        "\t\t\tkernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,\n",
        "\t\t\tactivity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n",
        "\t\t\tbias_constraint=None, dropout=0.0, recurrent_dropout=0.0,\n",
        "\t\t\treturn_sequences=False, return_state=False, go_backwards=False, stateful=False,\n",
        "\t\t\ttime_major=False, unroll=False, name='block1_lstm1'\n",
        "\t\t))\n",
        "\n",
        "\t\t#model.add(Bidirectional(LSTM(\n",
        "\t\t#\tunits = block_1_layers, activation='tanh', recurrent_activation='sigmoid',\n",
        "\t\t#\tuse_bias=True, kernel_initializer='glorot_uniform',\n",
        "\t\t#\trecurrent_initializer='orthogonal',\n",
        "\t\t#\tbias_initializer='zeros', unit_forget_bias=True,\n",
        "\t\t#\tkernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,\n",
        "\t\t#\tactivity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n",
        "\t\t#\tbias_constraint=None, dropout=0.0, recurrent_dropout=0.0,\n",
        "\t\t#\treturn_sequences=False, return_state=False, go_backwards=False, stateful=False,\n",
        "\t\t#\ttime_major=False, unroll=False, name='block1_lstm1'\n",
        "\t\t#)))\n",
        "\t\t#model.add(BatchNormalization(momentum=0.9, epsilon=1e-5, axis=1))\n",
        "\t\tmodel.add(Dense(block_1_layers, activation='relu', name='block1_dense1'))\n",
        "\t\tmodel.add(Dropout(0.1, name='block1_drop1'))\n",
        "\n",
        "\t\t#model.add(LSTM(units = block2_layers, activation='tanh', recurrent_activation='sigmoid', use_bias=True, name='block2_lstm1'))\n",
        "\t\tmodel.add(Dense(block2_layers, activation='relu', name='block2_dense1'))\n",
        "\t\t#model.add(Flatten(name='block1_flat1'))\n",
        "\t\tmodel.add(Dropout(0.1, name='block2_drop1'))\n",
        "\n",
        "\t\tmodel.add(BatchNormalization(momentum=0.9, epsilon=1e-5, axis=1))\n",
        "\n",
        "\t\t#model.add(LSTM(units = block3_layers, activation='tanh', recurrent_activation='sigmoid', use_bias=True, kernel_initializer='glorot_uniform', name='block3_lstm1'))\n",
        "\t\tmodel.add(Dense(block3_layers, activation='relu', name='block3_dense1'))\n",
        "\t\t#model.add(MaxoutDense(512, nb_feature=4, name=\"block2_maxout2\"))\n",
        "\t\tmodel.add(Dropout(0.1, name='block3_drop1'))\n",
        "\n",
        "\t\t#model.add(Dense(16, activation='relu', name='block2_dense3', input_dim=5,\n",
        "\t\t#\tkernel_initializer='ones',\n",
        "\t\t#\tkernel_regularizer=tf.keras.regularizers.L1(0.01),\n",
        "\t\t#\tactivity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
        "\n",
        "\t\t################################################################################\n",
        "\t\t#model.add(Reshape((None, self.y_tr.shape[1]), name='block4_reshape1'))\n",
        "\t\tmodel.add(Flatten(name='predict_flatten1'))\n",
        "\t\tmodel.add(Dense(\n",
        "\t\t\t\t\tself.y_tr.shape[1],\n",
        "\t\t\t\t\tactivation='softmax',\n",
        "\t\t\t\t\tname=\"predict\"\n",
        "\t\t\t\t))\n",
        "\t\tself.model = model\n",
        "\n",
        "\t\t#Define logger\n",
        "\t\tself.logger = keras.callbacks.TensorBoard(\n",
        "\t\t\tlog_dir='logs',\n",
        "\t\t\twrite_graph=True,\n",
        "\t\t\thistogram_freq=2\n",
        "\t\t)\n",
        "\t\t# Compile the model\n",
        "\t\tself.model.compile(\n",
        "\t\t\t\tloss='categorical_crossentropy',\n",
        "\t\t\t\t#optimizer=\"adam\",\n",
        "\t\t\t\toptimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "\t\t\t\t#optimizer='rmsprop',\n",
        "\t\t\t\t#optimizer=tf.keras.optimizers.Adam(\n",
        "\t\t\t\t#\t\tlearning_rate=0.1,\n",
        "\t\t\t\t#\t\tbeta_1=0.9,\n",
        "\t\t\t\t#\t\tbeta_2=0.999,\n",
        "\t\t\t\t#\t\tepsilon=1e-07,\n",
        "\t\t\t\t#\t\tamsgrad=False,\n",
        "\t\t\t\t#\t),\n",
        "\t\t\t\t#optimizer=tf.keras.optimizers.SGD(learning_rate=0.00001, momentum=0.005, decay=0.0004),\n",
        "\t\t\t\tmetrics=['accuracy', self.precision_m, self.recall_m]\n",
        "\t\t\t\t#metrics=[metrics]\n",
        "\t\t\t)\n",
        "\t\tfor i in range(1,len(model.layers)):\n",
        "\t\t\tprint(model.layers[i-1].output_shape, model.layers[i].input_shape, model.layers[i-1].output_shape == model.layers[i].input_shape)\n",
        "\t\tprint(self.model.summary())\n",
        "\n",
        "\tdef trainAndSaveModel(self):\n",
        "\t\t# self.X_tr.shape => (14834, 784)\n",
        "\t\t# self.y_tr.shape => (14834, 1)\n",
        "\t\t# unique label - 1202 (by set) / 1204(by categorical)\n",
        "\t\t# Fit the RNN - Training\n",
        "\t\thistory = self.model.fit(\n",
        "\t\t\t\t\t\tself.X_tr,\n",
        "\t\t\t\t\t\tself.y_tr,\n",
        "\t\t\t\t\t\tbatch_size = self.batch_size,\n",
        "\t\t\t\t\t\tepochs = self.epochs,\n",
        "\t\t\t\t\t\tvalidation_data = (self.X_test, self.y_test),\n",
        "\t\t\t\t\t\tshuffle = True,\n",
        "\t\t\t\t\t\tverbose = 2,\n",
        "\t\t\t\t\t\tcallbacks = [self.logger]\n",
        "\t\t\t\t\t)\n",
        "\t\tprint(history)\n",
        "\t\ttest_error_rate = self.model.evaluate(self.X_test, self.y_test, verbose=1)\n",
        "\t\tprint(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
        "\t\t#Save the model\n",
        "\t\ttry:\n",
        "\t\t\tpickle.dump(self.model, open(Utils.getAbsFilePath(self.model_filename), 'wb'))\t#Store Model to File\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"CNN-Model Save Failed\")\n",
        "\t\t\tprint(e)\n",
        "\t\treturn\n",
        "\n",
        "\tdef restoreModel(self):\n",
        "\t\ttry:\n",
        "\t\t\tself.model = pickle.load(open(Utils.getAbsFilePath(self.model_filename), 'rb'))\n",
        "\t\t\tresult = self.model.score(self.X_test, self.y_test)\n",
        "\t\t\tprint(result)\n",
        "\t\t\tprint(\"CNN-Model Loaded Successfully\")\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(\"CNN-Model Loaded Failed\")\n",
        "\t\t\tprint(e)\n",
        "\n",
        "\tdef savePrediction(self, X_pred, embedding = \"sbert\", output_file_name = str(math.ceil(datetime.datetime.now().timestamp()))+\"_submission.csv\"):\n",
        "\t\t#x_pred_reshaped = X_pred.values.reshape(X_pred.values.shape[0], self.dimention, self.dimention, 1)\n",
        "\t\tx_pred_reshaped = X_pred.values.reshape(X_pred.values.shape[0], X_pred.values.shape[1], 1)\n",
        "\t\ty_pred = self.model.predict(x_pred_reshaped)\n",
        "\t\ty_pred = list(map(np.argmax, y_pred))\n",
        "\t\tdf = pd.DataFrame({'id':list(X_pred.index),'labels': list(y_pred)})\n",
        "\t\tdf = df.set_index(['id'])\n",
        "\t\tdf.to_csv(Utils.getAbsFilePath(output_file_name))\n",
        "\t\treturn df"
      ],
      "metadata": {
        "id": "OVRMscMw67Qy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}